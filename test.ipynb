{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0b12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DINOv2 Preprocessor Output Demo\n",
      "================================================================================\n",
      "\n",
      "1. Loading DINOv2 image processor...\n",
      "   Processor type: <class 'transformers.models.bit.image_processing_bit.BitImageProcessor'>\n",
      "   Processor config: BitImageProcessor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"do_center_crop\": true,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"BitImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 256\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "2. Loading sample images from CIFAR-10...\n",
      "   Loaded 4 images\n",
      "   Original image type: <class 'PIL.Image.Image'>\n",
      "   Original image size: (32, 32)\n",
      "   Labels: [6, 9, 9, 4]\n",
      "\n",
      "3. Displaying original images...\n",
      "\n",
      "4. Processing images with DINOv2 processor...\n",
      "\n",
      "5. Processor Output Structure:\n",
      "================================================================================\n",
      "   Type: <class 'transformers.image_processing_base.BatchFeature'>\n",
      "   Keys: KeysView({'pixel_values': tensor([[[[-1.8268, -1.7583, -1.6898,  ..., -0.1143, -0.1143, -0.1143],\n",
      "          [-1.7583, -1.6727, -1.6042,  ..., -0.1143, -0.1143, -0.0972],\n",
      "          [-1.6727, -1.5870, -1.5185,  ..., -0.0972, -0.0972, -0.0972],\n",
      "          ...,\n",
      "          [ 1.2557,  1.2557,  1.2728,  ...,  0.4508,  0.2111, -0.0287],\n",
      "          [ 1.2214,  1.2214,  1.2385,  ...,  0.5022,  0.2796,  0.0227],\n",
      "          [ 1.1700,  1.1872,  1.2043,  ...,  0.5536,  0.3481,  0.1083]],\n",
      "\n",
      "         [[-1.9307, -1.8782, -1.8431,  ..., -0.5826, -0.6001, -0.6001],\n",
      "          [-1.8782, -1.8256, -1.7731,  ..., -0.5826, -0.5826, -0.5826],\n",
      "          [-1.8256, -1.7731, -1.7206,  ..., -0.5651, -0.5826, -0.5826],\n",
      "          ...,\n",
      "          [ 0.6604,  0.7129,  0.7304,  ...,  0.1001, -0.1275, -0.3725],\n",
      "          [ 0.6078,  0.6604,  0.6779,  ...,  0.1176, -0.0924, -0.3375],\n",
      "          [ 0.5553,  0.5903,  0.6254,  ...,  0.1527, -0.0399, -0.2850]],\n",
      "\n",
      "         [[-1.8044, -1.8044, -1.8044,  ..., -0.9504, -0.9678, -0.9678],\n",
      "          [-1.8044, -1.8044, -1.7696,  ..., -0.9504, -0.9504, -0.9504],\n",
      "          [-1.8044, -1.7696, -1.7347,  ..., -0.9330, -0.9330, -0.9330],\n",
      "          ...,\n",
      "          [-1.3339, -1.3513, -1.3513,  ..., -0.6890, -0.8458, -1.0027],\n",
      "          [-1.3339, -1.3513, -1.3513,  ..., -0.6367, -0.7936, -0.9678],\n",
      "          [-1.3513, -1.3513, -1.3687,  ..., -0.5844, -0.7413, -0.8981]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0741,  0.0227, -0.0287,  ..., -0.6623, -0.7137, -0.7308],\n",
      "          [ 0.0398, -0.0116, -0.0801,  ..., -0.7137, -0.7479, -0.7822],\n",
      "          [ 0.0227, -0.0458, -0.0972,  ..., -0.7479, -0.7993, -0.8164],\n",
      "          ...,\n",
      "          [ 0.5536,  0.5707,  0.5707,  ..., -1.2445, -1.1932, -1.1418],\n",
      "          [ 0.5707,  0.5878,  0.5878,  ..., -1.1247, -1.0562, -1.0219],\n",
      "          [ 0.5878,  0.6049,  0.6049,  ..., -0.9705, -0.9192, -0.8678]],\n",
      "\n",
      "         [[ 0.2402,  0.1702,  0.1176,  ..., -0.4951, -0.5476, -0.5826],\n",
      "          [ 0.2052,  0.1176,  0.0826,  ..., -0.5476, -0.5826, -0.6176],\n",
      "          [ 0.1877,  0.1001,  0.0476,  ..., -0.5826, -0.6352, -0.6702],\n",
      "          ...,\n",
      "          [ 0.7479,  0.7829,  0.8004,  ..., -1.3004, -1.2304, -1.1954],\n",
      "          [ 0.7654,  0.8004,  0.8179,  ..., -1.1779, -1.1253, -1.0728],\n",
      "          [ 0.7654,  0.8004,  0.8179,  ..., -1.0203, -0.9678, -0.9153]],\n",
      "\n",
      "         [[ 0.4265,  0.3219,  0.2522,  ..., -0.6193, -0.6367, -0.6890],\n",
      "          [ 0.3916,  0.2871,  0.2173,  ..., -0.6541, -0.6715, -0.7238],\n",
      "          [ 0.3742,  0.2696,  0.1999,  ..., -0.6890, -0.7064, -0.7413],\n",
      "          ...,\n",
      "          [ 1.0539,  1.0888,  1.1062,  ..., -1.0201, -0.9678, -0.9156],\n",
      "          [ 1.0017,  1.0365,  1.0539,  ..., -0.8981, -0.8458, -0.7936],\n",
      "          [ 0.9145,  0.9668,  0.9842,  ..., -0.7587, -0.7064, -0.6367]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          [ 2.2318,  2.2318,  2.2318,  ...,  2.2318,  2.2318,  2.2318],\n",
      "          ...,\n",
      "          [-0.2856, -0.3027, -0.3198,  ..., -0.8849, -0.8849, -0.8849],\n",
      "          [-0.3027, -0.3198, -0.3369,  ..., -0.9020, -0.9020, -0.8849],\n",
      "          [-0.3198, -0.3198, -0.3541,  ..., -0.9192, -0.9192, -0.9020]],\n",
      "\n",
      "         [[ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
      "          ...,\n",
      "          [-0.0399, -0.0574, -0.0749,  ..., -0.6352, -0.6352, -0.6352],\n",
      "          [-0.0574, -0.0749, -0.0924,  ..., -0.6527, -0.6527, -0.6527],\n",
      "          [-0.0749, -0.0749, -0.1099,  ..., -0.6702, -0.6702, -0.6702]],\n",
      "\n",
      "         [[ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          [ 2.6226,  2.6226,  2.6226,  ...,  2.6226,  2.6226,  2.6226],\n",
      "          ...,\n",
      "          [ 0.0779,  0.0605,  0.0431,  ..., -0.4275, -0.4275, -0.4275],\n",
      "          [ 0.0605,  0.0431,  0.0256,  ..., -0.4450, -0.4450, -0.4450],\n",
      "          [ 0.0431,  0.0256, -0.0092,  ..., -0.4798, -0.4798, -0.4798]]],\n",
      "\n",
      "\n",
      "        [[[-1.4158, -1.3987, -1.3815,  ..., -0.4568, -0.4397, -0.4054],\n",
      "          [-1.3644, -1.3473, -1.3130,  ..., -0.4568, -0.4397, -0.4054],\n",
      "          [-1.3130, -1.2959, -1.2617,  ..., -0.4739, -0.4397, -0.4054],\n",
      "          ...,\n",
      "          [-0.6452, -0.6623, -0.6452,  ..., -0.4739, -0.4911, -0.5082],\n",
      "          [-0.6281, -0.6452, -0.6281,  ..., -0.5082, -0.5253, -0.5424],\n",
      "          [-0.6109, -0.6109, -0.6109,  ..., -0.5424, -0.5596, -0.5767]],\n",
      "\n",
      "         [[-1.4230, -1.4055, -1.3880,  ..., -0.6176, -0.5826, -0.5651],\n",
      "          [-1.3880, -1.3529, -1.3354,  ..., -0.6352, -0.6001, -0.5826],\n",
      "          [-1.3354, -1.3004, -1.2829,  ..., -0.6527, -0.6176, -0.5826],\n",
      "          ...,\n",
      "          [-0.7227, -0.7402, -0.7402,  ..., -0.4601, -0.4776, -0.4951],\n",
      "          [-0.7227, -0.7227, -0.7227,  ..., -0.4951, -0.5126, -0.5301],\n",
      "          [-0.7227, -0.7227, -0.7227,  ..., -0.5301, -0.5476, -0.5651]],\n",
      "\n",
      "         [[-1.4733, -1.4559, -1.4384,  ..., -0.8458, -0.7936, -0.7761],\n",
      "          [-1.4384, -1.4210, -1.3861,  ..., -0.8458, -0.8110, -0.7761],\n",
      "          [-1.4036, -1.3687, -1.3339,  ..., -0.8633, -0.8110, -0.7761],\n",
      "          ...,\n",
      "          [-0.8633, -0.8807, -0.8981,  ..., -0.6193, -0.6367, -0.6541],\n",
      "          [-0.8633, -0.8633, -0.8807,  ..., -0.6541, -0.6715, -0.6890],\n",
      "          [-0.8633, -0.8633, -0.8807,  ..., -0.6890, -0.7064, -0.7238]]]])})\n",
      "\n",
      "   'pixel_values':\n",
      "      - Type: <class 'torch.Tensor'>\n",
      "      - Shape: torch.Size([4, 3, 224, 224])\n",
      "      - Dtype: torch.float32\n",
      "      - Min value: -2.1179\n",
      "      - Max value: 2.6400\n",
      "      - Mean: -0.0291\n",
      "      - Std: 1.0734\n",
      "\n",
      "\n",
      "6. Visualizing preprocessed images...\n",
      "   Normalization mean: [0.485, 0.456, 0.406]\n",
      "   Normalization std: [0.229, 0.224, 0.225]\n",
      "\n",
      "7. Testing with DINOv2 model (forward pass)...\n",
      "   Model output keys: odict_keys(['last_hidden_state', 'pooler_output'])\n",
      "   last_hidden_state shape: torch.Size([4, 257, 768])\n",
      "   pooler_output shape: torch.Size([4, 768])\n",
      "\n",
      "8. Token Structure:\n",
      "   Total sequence length: 257\n",
      "   CLS token: index 0, shape: torch.Size([4, 768])\n",
      "   Patch tokens: indices 1:, shape: torch.Size([4, 256, 768])\n",
      "   Number of patches: 256\n",
      "   Patches per side: 16x16\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 135\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Number of patches: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_patches\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    134\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Patches per side: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatches_per_side\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatches_per_side\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Patch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mheight\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39mpatches_per_side\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessor.size[\u001b[33m'\u001b[39m\u001b[33mwidth\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39mpatches_per_side\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m    138\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSummary:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'height'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DINOv2 Preprocessor Output Demonstration\n",
    "\n",
    "This script shows what the DINOv2 image processor returns when preprocessing\n",
    "a batch of images from a torchvision dataset.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DINOv2 Preprocessor Output Demo\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load DINOv2 processor\n",
    "print(\"\\n1. Loading DINOv2 image processor...\")\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "print(f\"   Processor type: {type(processor)}\")\n",
    "print(f\"   Processor config: {processor}\")\n",
    "\n",
    "# Load a small dataset from torchvision (CIFAR-10 for demo)\n",
    "print(\"\\n2. Loading sample images from CIFAR-10...\")\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=None  # We'll use the processor instead\n",
    ")\n",
    "\n",
    "# Get a batch of images\n",
    "batch_size = 4\n",
    "images = [dataset[i][0] for i in range(batch_size)]\n",
    "labels = [dataset[i][1] for i in range(batch_size)]\n",
    "\n",
    "print(f\"   Loaded {batch_size} images\")\n",
    "print(f\"   Original image type: {type(images[0])}\")\n",
    "print(f\"   Original image size: {images[0].size}\")\n",
    "print(f\"   Labels: {labels}\")\n",
    "\n",
    "# Display original images\n",
    "print(\"\\n3. Displaying original images...\")\n",
    "fig, axes = plt.subplots(1, batch_size, figsize=(12, 3))\n",
    "for idx, (img, label) in enumerate(zip(images, labels)):\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(f\"Label: {label}\")\n",
    "    axes[idx].axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Process images with DINOv2 processor\n",
    "print(\"\\n4. Processing images with DINOv2 processor...\")\n",
    "inputs = processor(images=images, return_tensors=\"pt\")\n",
    "\n",
    "print(\"\\n5. Processor Output Structure:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"   Type: {type(inputs)}\")\n",
    "print(f\"   Keys: {inputs.keys()}\")\n",
    "print()\n",
    "\n",
    "for key, value in inputs.items():\n",
    "    print(f\"   '{key}':\")\n",
    "    print(f\"      - Type: {type(value)}\")\n",
    "    print(f\"      - Shape: {value.shape}\")\n",
    "    print(f\"      - Dtype: {value.dtype}\")\n",
    "    print(f\"      - Min value: {value.min().item():.4f}\")\n",
    "    print(f\"      - Max value: {value.max().item():.4f}\")\n",
    "    print(f\"      - Mean: {value.mean().item():.4f}\")\n",
    "    print(f\"      - Std: {value.std().item():.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize the preprocessed images (denormalize for visualization)\n",
    "print(\"\\n6. Visualizing preprocessed images...\")\n",
    "pixel_values = inputs['pixel_values']\n",
    "\n",
    "# Get normalization stats from processor\n",
    "mean = processor.image_mean\n",
    "std = processor.image_std\n",
    "print(f\"   Normalization mean: {mean}\")\n",
    "print(f\"   Normalization std: {std}\")\n",
    "\n",
    "# Denormalize for visualization\n",
    "mean_tensor = torch.tensor(mean).view(3, 1, 1)\n",
    "std_tensor = torch.tensor(std).view(3, 1, 1)\n",
    "denormalized = pixel_values * std_tensor + mean_tensor\n",
    "\n",
    "# Convert to numpy and transpose for matplotlib (C, H, W) -> (H, W, C)\n",
    "denormalized_np = denormalized.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "# Clip values to [0, 1] range\n",
    "denormalized_np = np.clip(denormalized_np, 0, 1)\n",
    "\n",
    "fig, axes = plt.subplots(2, batch_size, figsize=(12, 6))\n",
    "for idx in range(batch_size):\n",
    "    # Original\n",
    "    axes[0, idx].imshow(images[idx])\n",
    "    axes[0, idx].set_title(f\"Original (Label: {labels[idx]})\")\n",
    "    axes[0, idx].axis('off')\n",
    "    \n",
    "    # Preprocessed (denormalized)\n",
    "    axes[1, idx].imshow(denormalized_np[idx])\n",
    "    axes[1, idx].set_title(f\"Preprocessed\")\n",
    "    axes[1, idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Test with the model to see the full pipeline\n",
    "print(\"\\n7. Testing with DINOv2 model (forward pass)...\")\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "print(f\"   Model output keys: {outputs.keys()}\")\n",
    "print(f\"   last_hidden_state shape: {outputs.last_hidden_state.shape}\")\n",
    "print(f\"   pooler_output shape: {outputs.pooler_output.shape}\")\n",
    "\n",
    "# Analyze the sequence structure\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "print(f\"\\n8. Token Structure:\")\n",
    "print(f\"   Total sequence length: {last_hidden_state.shape[1]}\")\n",
    "print(f\"   CLS token: index 0, shape: {last_hidden_state[:, 0, :].shape}\")\n",
    "print(f\"   Patch tokens: indices 1:, shape: {last_hidden_state[:, 1:, :].shape}\")\n",
    "\n",
    "# Calculate number of patches\n",
    "num_patches = last_hidden_state.shape[1] - 1\n",
    "patches_per_side = int(np.sqrt(num_patches))\n",
    "print(f\"   Number of patches: {num_patches}\")\n",
    "print(f\"   Patches per side: {patches_per_side}x{patches_per_side}\")\n",
    "print(f\"   Patch size: {processor.size['height'] // patches_per_side}x{processor.size['width'] // patches_per_side}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Input images: {batch_size} images\")\n",
    "print(f\"✓ Processor output: 'pixel_values' tensor of shape {inputs['pixel_values'].shape}\")\n",
    "print(f\"✓ Format: (batch_size, channels, height, width)\")\n",
    "print(f\"✓ Normalized with mean={mean}, std={std}\")\n",
    "print(f\"✓ Model output: last_hidden_state of shape {outputs.last_hidden_state.shape}\")\n",
    "print(f\"✓ Token structure: 1 CLS token + {num_patches} patch tokens\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
